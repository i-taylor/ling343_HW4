---
title: "HW4_Isaactay"
author: "Isaac Taylor"
format: 
  html:
    embed-resources: true
editor: visual
---

```{r}
# Install packages
# install.packages("RedditExtractoR")
# install.packages("tidytext")
# install.packages("ggplot2")
# install.packages("dplyr")

# Load packages
library(RedditExtractoR)
library(tidytext)
library(ggplot2)
library(dplyr)
library(here)
library(tidyverse)

```

```{r}
# run this code to save the rds file
# top_sw_urls <- find_thread_urls(subreddit="StarWars", sort_by="top")

# write_rds(top_sw_urls, here("top_sw_urls.rds"))
top_sw_urls <- read_rds(here("top_sw_urls.rds"))

```

```{r}
# Tokenize and clean up the text
tidy_words <- top_sw_urls %>%
  unnest_tokens(word, title) %>%  # Tokenize words from the post titles
  anti_join(stop_words) %>%      # Removing stopwords
  count(word, sort = TRUE)       # Count the word frequencies
```

```{r}
# Visualize top words
tidy_words %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_bar(stat = "identity", fill = "blue") +
  coord_flip() +
  labs(title = "Top 10 Words in r/StarWars Subreddit",
       x = "Word", y = "Frequency")
```

```{r}
# hbo_user <- get_user_content("hbomax")
# write_rds(hbo_user, here("hbomax.rds"))
hbo_user <- read_rds(here("hbomax.rds"))


basecomments <- hbo_user[["hbomax"]]$comment |>
  tibble() |> 
  filter(score > 40)

basecomments

user_words <- basecomments %>%
  unnest_tokens(word, comment) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE)

user_words %>%
  top_n(10, n) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_bar(stat = "identity", fill = "green") +
  coord_flip() +
  labs(title = "Top 10 Words in User Comments",
       x = "Word", y = "Frequency")


```

```{r}


```
